{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "You will perform a statistical analysis to establish whether race has a significant impact on the rate of callbacks for resumes.\n",
    "\n",
    "Answer the following questions **in this notebook below and submit to your Github account**. \n",
    "\n",
    "   1. What test is appropriate for this problem? Does CLT apply?\n",
    "   2. What are the null and alternate hypotheses?\n",
    "   3. Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.\n",
    "   4. Write a story describing the statistical significance in the context or the original problem.\n",
    "   5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "#### Resources\n",
    "+ Experiment information and data source: http://www.povertyactionlab.org/evaluation/discrimination-job-market-united-states\n",
    "+ Scipy statistical methods: http://docs.scipy.org/doc/scipy/reference/stats.html \n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "+ Formulas for the Bernoulli distribution: https://en.wikipedia.org/wiki/Bernoulli_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of callbacks for black-sounding names\n",
    "sum(data[data.race=='w'].call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ad</th>\n",
       "      <th>education</th>\n",
       "      <th>ofjobs</th>\n",
       "      <th>yearsexp</th>\n",
       "      <th>honors</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>military</th>\n",
       "      <th>empholes</th>\n",
       "      <th>occupspecific</th>\n",
       "      <th>...</th>\n",
       "      <th>compreq</th>\n",
       "      <th>orgreq</th>\n",
       "      <th>manuf</th>\n",
       "      <th>transcom</th>\n",
       "      <th>bankreal</th>\n",
       "      <th>trade</th>\n",
       "      <th>busservice</th>\n",
       "      <th>othservice</th>\n",
       "      <th>missind</th>\n",
       "      <th>ownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nonprofit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ad  education  ofjobs  yearsexp  honors  volunteer  military  empholes  \\\n",
       "0  b  1          4       2         6       0          0         0         1   \n",
       "1  b  1          3       3         6       0          1         1         0   \n",
       "2  b  1          4       1         6       0          0         0         0   \n",
       "3  b  1          3       4         6       0          1         0         1   \n",
       "4  b  1          3       3        22       0          0         0         0   \n",
       "\n",
       "   occupspecific  ...  compreq  orgreq  manuf  transcom  bankreal trade  \\\n",
       "0             17  ...      1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "1            316  ...      1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "2             19  ...      1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "3            313  ...      1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "4            313  ...      1.0     1.0    0.0       0.0       0.0   0.0   \n",
       "\n",
       "  busservice othservice  missind  ownership  \n",
       "0        0.0        0.0      0.0             \n",
       "1        0.0        0.0      0.0             \n",
       "2        0.0        0.0      0.0             \n",
       "3        0.0        0.0      0.0             \n",
       "4        0.0        1.0      0.0  Nonprofit  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to check the requirements of CLT and check for normality (using a Q-Q Plot).\n",
    "The requirements of the CLT:\n",
    "1. Large enough sample size (>=30)\n",
    "2. Independent Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4870 entries, 0 to 4869\n",
      "Data columns (total 2 columns):\n",
      "race    4870 non-null object\n",
      "call    4870 non-null float32\n",
      "dtypes: float32(1), object(1)\n",
      "memory usage: 95.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_race = data.loc[:,['race','call']]\n",
    "data_race.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There are 4870 observations making this data set large enough for the CLT to apply.\n",
    "2. The samples are independent of each other as they represent individual observations of resumes. One resume has no knowing impact on another resume being submitted.\n",
    "\n",
    "The data we're looking at is a discrete distribution (as opposed to continuous). In fact, it is even more restricted, we're working with binary distributed data, meaning a Bernoulli Trial seems an appropriate test setup.\n",
    "\n",
    "There is a couple assumptions we can make using this binomial model:\n",
    "- The number of r successes in n Bernoulli trials with probability p of success, is Binomially distributed.\n",
    "- The Central Limit Theorem applies as long as min(np, n(1-p)) >= 5\n",
    "\n",
    "Let's explore the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Resumes: 4870\n",
      "Resumes by Race: black (b) = 2435 white (w) = 2435\n",
      "Call Ratio: 0.08049281314168377\n"
     ]
    }
   ],
   "source": [
    "n = len(data_race)\n",
    "print(\"Total Number of Resumes: {}\".format(n))\n",
    "\n",
    "b_resumes = data_race['race'] == 'b'\n",
    "w_resumes = data_race['race'] == 'w'\n",
    "print(\"Resumes by Race: black (b) = {} white (w) = {}\".format(np.sum(b_resumes),np.sum(w_resumes)))\n",
    "\n",
    "callbacks = data_race['call'] == 1\n",
    "call_ratio = np.sum(callbacks)/len(data_race)\n",
    "print(\"Call Ratio: {}\".format(call_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the resumes were perfectly split between white-sounding and black-sounding names. It is also important to note that the call ratio is quite low overall with slightly over 8% of all resumes receiving a call.\n",
    "\n",
    "If the probability to receive a call for a white-sounding name and a black-sounding name is the same then we shouldn't see any significant differences between these two groups in our sample.\n",
    "\n",
    "    H0: The difference of callback ratios between white- and black-sounding names is 0.\n",
    "    H1: The difference of callback ratios between white- and black-sounding names is not 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = data[data.race=='w']\n",
    "b = data[data.race=='b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a Bernoulli Trial with the Bootstrap method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback Ratio for Black: 0.06447638603696099\n",
      "Callback Ratio for White: 0.09650924024640657\n",
      "Difference between Black and White Calls for Interviews: -0.032032854209445585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16098562628336754"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_ratio(data):\n",
    "    return np.sum(data == 1) / len(data)\n",
    "\n",
    "b_callratio = generate_ratio(b.call)\n",
    "w_callratio = generate_ratio(w.call)\n",
    "\n",
    "print(\"Callback Ratio for Black: {}\".format(b_callratio))\n",
    "print(\"Callback Ratio for White: {}\".format(w_callratio))\n",
    "   \n",
    "# Define Comparison Function Difference of Ratios\n",
    "def ratio_diff(data1,data2):\n",
    "    ratio1 = generate_ratio(data1)\n",
    "    ratio2 = generate_ratio(data2)\n",
    "    return ratio1 - ratio2\n",
    "\n",
    "b_w_diff = ratio_diff(b.call,w.call)\n",
    "print(\"Difference between Black and White Calls for Interviews: {}\".format(b_w_diff))\n",
    "\n",
    "b_callratio + w_callratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a few utility functions for Q-Q plots and ECDF\n",
    "def ecdf(data):\n",
    "    \"\"\"\n",
    "    Returns the x,y values for data for plotting as an ecdf.\n",
    "    \"\"\"\n",
    "    # Sort the data along the x-axis\n",
    "    x = np.sort(data)\n",
    "    # Index the data at equidistant intervals\n",
    "    y = np.arange(1, len(x) + 1) / len(x)\n",
    "    return x,y\n",
    "\n",
    "def lreg_line(slope,intercept,test_data):\n",
    "    x_lreg = np.array([min(test_data),max(test_data)])\n",
    "    y_lreg = slope * x_lreg + intercept\n",
    "    return x_lreg,y_lreg\n",
    "        \n",
    "def qq(data):\n",
    "    (x,y), (slope,intercept,r) = stats.probplot(data, dist=\"norm\", plot=None)\n",
    "    _ = plt.plot(x,y,marker='.',linestyle='none',color='red',alpha=0.5)\n",
    "    x_lreg,y_lreg = lreg_line(slope,intercept,x)\n",
    "    return (x_lreg,y_lreg),(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed Random\n",
    "np.random.seed(500)\n",
    "\n",
    "def bins_rule_of_thumb(data):\n",
    "    return int(np.sqrt(len(data)))\n",
    "\n",
    "# Create Permutation Sample Function\n",
    "def permutation_sample(data1,data2):\n",
    "    \"\"\"\n",
    "    Creates a Permutation Sample from two data sets and returns two permutated samples \n",
    "    with the same length as the original sets.\n",
    "    \"\"\"\n",
    "    data_both = np.concatenate((data1,data2))\n",
    "    data_perm = np.random.permutation(data_both)\n",
    "    perm_sample_1 = data_perm[:len(data1)]\n",
    "    perm_sample_2 = data_perm[len(data1):]\n",
    "    return (perm_sample_1,perm_sample_2)\n",
    "\n",
    "# Define function to generate Permutation Replicates\n",
    "def draw_perm_reps(data1,data2,func,size=1):\n",
    "    perm_replicates = np.empty(size)\n",
    "    \n",
    "    for i in range(size):\n",
    "        perm_sample_1,perm_sample_2 = permutation_sample(data1,data2)\n",
    "        perm_replicates[i] = func(perm_sample_1,perm_sample_2)\n",
    "        \n",
    "    return perm_replicates\n",
    "\n",
    "perm_replicates = draw_perm_reps(b.call,w.call,ratio_diff,10000)\n",
    "\n",
    "p = np.sum(perm_replicates <= b_w_diff) / len(perm_replicates)\n",
    "print(\"p: {}\".format(p))\n",
    "\n",
    "CI = np.percentile(perm_replicates,[2.5,97.5])\n",
    "print(\"CI: {}\".format(CI))\n",
    "\n",
    "ME = CI[1] - np.mean(perm_replicates)\n",
    "print(\"ME: {}\".format(ME))\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "_ = sns.distplot(perm_replicates,bins=25,color='gray')\n",
    "_ = plt.xlabel('Mean Difference of Callback Ratio')\n",
    "_ = plt.ylabel('Density')\n",
    "_ = plt.legend(['Callback Distribution \\nfor p(w)=p(b)'],loc='upper left')\n",
    "_ = plt.annotate(s='Point Estimate',xy=(b_w_diff,0),xytext=(b_w_diff,10),\n",
    "                 arrowprops={'width':1.5,'headwidth':5,'color': 'red'})\n",
    "\n",
    "\n",
    "## CI_area = perm_replicates[perm_replicates <= CI[0]]\n",
    "## _ = plt.hist(CI_area)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "x,y = ecdf(perm_replicates)\n",
    "y_interp = np.interp(x,x,y)\n",
    "_ = plt.plot(x,y_interp,color='gray')\n",
    "_ = plt.xlim([b_w_diff - 0.005,-b_w_diff + 0.005])\n",
    "\n",
    "_ = plt.xlabel('Mean Difference of Callback Ratio')\n",
    "_ = plt.ylabel('Cumulative Probability')\n",
    "_ = plt.legend(['Callback Distribution \\nfor p(w)=p(b)'],loc='upper left')\n",
    "_ = plt.annotate(s='Point Estimate',xy=(b_w_diff,0),xytext=(b_w_diff,0.2),\n",
    "                 arrowprops={'width':1.5,'headwidth':5,'color': 'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Interpretation:_ Using a permutation approach the Point Estimate Ratio Difference of -0.032 has a very low probability (i.e. we weren't able to generate a result as extreme as the original even once). The acceptable differences for a 95% Confidence Interval (p<0.05) are [-0.015, 0.016]. This puts the Point Estimate fairly out of a likely result if H0 was true.\n",
    "\n",
    "_Conclusion:_ Given the results above, we can reject H0 and have gathered evidence to support H1. The data indicates that there might be a bias towards white-sounding names and a bias against black-sounding names in the job application process.\n",
    "\n",
    "We'll validate our results using a frequentist approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportional Z-Test \n",
    "\n",
    "To set this test up we'll have to find the ratio difference and compare it to the combined proportion distribution.\n",
    "\n",
    "Formulas: \n",
    "- z=((x1-x2) - 0)/SE_x1_x2 -- Z Value (Ratio difference minus expected difference divided by combined standard deviation)\n",
    "- SE = sqrt(k\\*p\\*(1-p)/n) -- Standard Error for the Distribution of proportions of successes for Binomial Distributions follows approximately a normal distribution (k is the number of Bernoulli draws, usually 1) \n",
    "    - [more information](https://en.wikipedia.org/wiki/Binomial_distribution) on Wikipedia see _Normal Approximation_ and search for _proportion z-test_, also additional information on [p distribution](http://onlinestatbook.com/2/sampling_distributions/samp_dist_p.html)\n",
    "- SE_x1_x2=np.sqrt((SE_x1\\*\\*2) + (SE_x2\\*\\*2)) -- Sample Error for two ratio of success Binomial Distributions\n",
    "- CI +- Margin of Error (ME) -- Confidence Interval\n",
    "- ME = z_crit\\*SE -- Margin of Error\n",
    "\n",
    "Define the Hypotheses:\n",
    "(see above)\n",
    "\n",
    "95% Confidence Interval (CI) (alpha=0.05):\n",
    "- z_crit = -1.96/1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ratio difference was already generated in the Bootstrap approach\n",
    "print(\"Difference between Black and White Calls for Interviews: {}\".format(b_w_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Standard Deviation of the ratio of callbacks for black-sounding names\n",
    "# The distribution of the proportions of successes (not the distribution of successes) \n",
    "# approximately follows a normal distribution.\n",
    "n_b = len(b.call)\n",
    "p_b = generate_ratio(b.call)\n",
    "SE_b = np.sqrt(p_b * (1-p_b)/n_b)\n",
    "\n",
    "# Calculate the same for the ratio of callbacks for white-sounding names\n",
    "n_w = len(w.call)\n",
    "p_w = generate_ratio(w.call)\n",
    "SE_w = np.sqrt(p_w * (1-p_w)/n_w)\n",
    "\n",
    "# Calculate the combined Standard Error\n",
    "SE_b_w=np.sqrt(SE_b**2 + SE_w**2)\n",
    "print(\"SE: {}\".format(SE_b_w))\n",
    "\n",
    "# Calculate the Z Value\n",
    "z = ((b_w_diff) - ratio_diff_h0)/SE_b_w\n",
    "\n",
    "print(\"z: {}\".format(z))\n",
    "\n",
    "# Calculate the CI\n",
    "z_crit = 1.96\n",
    "ME = z_crit * SE_b_w\n",
    "CI = [0 - ME, 0 + ME]\n",
    "print(\"CI: {}\".format(CI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Interpretation:_ The z-value (-4.12) is far in the critical region <= -1.96 and can be considered unlikely to have been randomly drawn if the success proportions were equally distributed (holds true for p<0.001). The 95% Confidence Interval (p<0.05) states that for H0 to be an acceptable Hypothesis the difference of ratios would have to be >=-0.015 and <=0.015.\n",
    "\n",
    "_Conclusion:_ Again, we're able to reject H0 (p<0.001). This means that there is a significant difference between white- and black-sounding names in the job application process. It appears that black-sounding names have a lower rate of success to receive a call for an interview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Significance\n",
    "\n",
    "This analysis set out to see whether or not there is a racial bias in the job application process, specifically in terms of callback rates. To test the hypothesis 4870 resumes were sent out 50% with white-sounding names and 50% with black-sounding names.\n",
    "\n",
    "The results came back with a bias against black-sounding names. The rate at which black-sounding names received calls for interviews was about 1/3 below the rate of white-sounding names. To understand whether our hypothesis of no bias between black-sounding and white-sounding names could be rejected we used a bootstrap approach as well as a proportion Z-Test, both of which came back with the difference between these two groups being significant for a 95% confidence interval.\n",
    "\n",
    "I find it important to note that the Z-Value (-4.11) for the bias against black-sounding names signifies a strong significance and would hold up for p < 0.001, that means we can say with 99.9% certainty that black-sounding and white-sounding names on resumes are not treated impartially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Does this mean race/name is the most important factor?\n",
    "\n",
    "This experiment shows that there is a bias between white-sounding names and black-sounding names. However, since the resumes were identical it does not say that the name as a factor is the most influential to trigger a callback.\n",
    "\n",
    "To understand whether the name is the most influential factor for callback success, we would have to add another variable in terms of qualification. In the current test setup the resume variable is held constant, that allows us to compare names against each other but repeating this study by handing in resumes with different levels of qualifications will allow us to weigh the response rate. If we witness a significantly lower callback rates for black-sounding names with a higher education/experience than those for white-sounding names with an inferior education/experience background we can show that race/name indeed is the most important factor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
